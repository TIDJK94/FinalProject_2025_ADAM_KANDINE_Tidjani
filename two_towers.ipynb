{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27af0057",
   "metadata": {},
   "source": [
    "# Two towers implementation\n",
    "\n",
    "The Two Towers architecture is a popular neural network approach for recommender systems, especially when both user and item features are available. Hereâ€™s why it is used and how it works:\n",
    "\n",
    "**1. Flexible Feature Integration:**  \n",
    "The Two Towers model allows you to incorporate a wide range of user and item features (such as demographics, content tags, or behavioral data), not just interaction histories. This flexibility helps the model learn richer representations.\n",
    "\n",
    "**2. Scalability:**  \n",
    "By learning separate embeddings for users and items, the Two Towers approach enables efficient retrieval of recommendations, even in large-scale systems. After training, you can precompute embeddings and use fast similarity search for recommendations.\n",
    "\n",
    "**3. Generalization:**  \n",
    "Unlike traditional collaborative filtering, which relies solely on the interaction matrix, Two Towers can generalize to new users or items if their features are known, making it suitable for cold-start scenarios.\n",
    "\n",
    "**4. Architecture Overview:**  \n",
    "- **User Tower:** Processes user features and outputs a user embedding.\n",
    "- **Item Tower:** Processes item features and outputs an item embedding.\n",
    "- The similarity (often dot product or cosine similarity) between user and item embeddings predicts the likelihood of interaction.\n",
    "\n",
    "**5. Real-World Use:**  \n",
    "This architecture is widely used in industry (e.g., YouTube, Google, TikTok) for large-scale personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28996a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 19:57:53.188577: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-17 19:57:56.320521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747504677.901126  213913 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747504678.428914  213913 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747504679.868216  213913 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747504679.868712  213913 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747504679.868751  213913 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747504679.868757  213913 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-17 19:58:00.187025: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "import json\n",
    "import load_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a925635",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_matrix, big_matrix, item_categories, item_features, social_network, user_features, captions = load_data.load_data()\n",
    "\n",
    "item_features = item_features_agg = item_features.groupby(\"video_id\").agg({\n",
    "    \"play_cnt\": \"sum\",\n",
    "    \"share_cnt\": \"sum\",\n",
    "    \"download_cnt\": \"sum\",\n",
    "    \"comment_cnt\": \"sum\",\n",
    "    \"upload_type\": \"first\",\n",
    "    \"author_id\": \"first\",\n",
    "    \"video_duration\": \"first\"\n",
    "})\n",
    "item_features[\"video_duration\"] = item_features[\"video_duration\"].fillna(item_features[\"video_duration\"].median())\n",
    "item_features = item_features.dropna()\n",
    "item_features = item_features.drop_duplicates()\n",
    "all_categories = set(cat for sublist in item_categories[\"feat\"] for cat in sublist)\n",
    "for cat in all_categories:\n",
    "    item_features[f'cat_{cat}'] = item_categories[\"feat\"].apply(lambda x: int(cat in x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6fe7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved implementation of the Two Towers model\n",
    "\n",
    "# User tower\n",
    "user_input = Input(shape=(user_features.shape[1],), name='user_input')\n",
    "user_tower = Dense(128, activation='relu')(user_input)\n",
    "user_tower = Dropout(0.3)(user_tower)\n",
    "user_tower = Dense(64, activation='relu')(user_tower)\n",
    "user_tower = Dense(32, activation='relu')(user_tower)\n",
    "user_tower = Dropout(0.2)(user_tower)\n",
    "\n",
    "# Item tower\n",
    "item_input = Input(shape=(item_features.shape[1],), name='item_input')\n",
    "item_tower = Dense(128, activation='relu')(item_input)\n",
    "item_tower = Dropout(0.3)(item_tower)\n",
    "item_tower = Dense(64, activation='relu')(item_tower)\n",
    "item_tower = Dense(32, activation='relu')(item_tower)\n",
    "item_tower = Dropout(0.2)(item_tower)\n",
    "\n",
    "# Concatenate towers\n",
    "merged = Concatenate()([user_tower, item_tower])\n",
    "merged = Dense(64, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = Dense(32, activation='relu')(merged)\n",
    "output = Dense(1, activation='linear', name='output')(merged)\n",
    "\n",
    "model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Callbacks for better training\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb19d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels of string columns\n",
    "item_features[\"upload_type\"] = LabelEncoder().fit_transform(item_features[\"upload_type\"])\n",
    "user_features[\"user_active_degree\"] = LabelEncoder().fit_transform(user_features[\"user_active_degree\"])\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "user_features = StandardScaler().fit_transform(user_features)\n",
    "item_features = StandardScaler().fit_transform(item_features)\n",
    "watch_ratios = StandardScaler().fit_transform(big_matrix[[\"watch_ratio\"]].values)\n",
    "\n",
    "# Split into train and test\n",
    "\n",
    "user_features_train = user_features[big_matrix[\"user_id\"]]\n",
    "item_features_train = item_features[big_matrix[\"video_id\"]]\n",
    "y_train = watch_ratios\n",
    "\n",
    "\n",
    "user_features_test = user_features[small_matrix[\"user_id\"]]\n",
    "item_features_test = item_features[small_matrix[\"video_id\"]]\n",
    "y_test = StandardScaler().fit_transform(small_matrix[[\"watch_ratio\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=[user_features_train, item_features_train],\n",
    "    y=y_train,\n",
    "    validation_data=([user_features_test, item_features_test], y_test),\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")\n",
    "\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d357d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model\n",
    "two_tower_model = load_model(\"two-towers.keras\", custom_objects={'tf': tf})\n",
    "\n",
    "inverse_scaler = StandardScaler().fit(big_matrix[[\"watch_ratio\"]].values)\n",
    "\n",
    "y_true = inverse_scaler.inverse_transform(y_test).flatten()\n",
    "\n",
    "predictions = model.predict([user_features_test, item_features_test])\n",
    "y_pred = inverse_scaler.inverse_transform(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2c21103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model\n",
      "True values: [0.71234272 2.17924934 2.37223467 0.51962865 0.33643166]\n",
      "Predicted values: [[1.4275737 ]\n",
      " [1.4261898 ]\n",
      " [0.90504426]\n",
      " [1.2559516 ]\n",
      " [0.9100992 ]]\n",
      "MAE: 0.5125399806729959\n",
      "RMSE: 1.6252481923620308\n",
      "R2: 0.06278182109012642\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Evaluate the model\")\n",
    "print(f\"True values: {y_true[:5]}\")\n",
    "print(f\"Predicted values: {y_pred[:5]}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2: {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
