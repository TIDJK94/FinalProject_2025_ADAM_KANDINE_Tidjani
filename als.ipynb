{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8b05ea",
   "metadata": {},
   "source": [
    "# Alternating Least Squares (ALS) Model\n",
    "\n",
    "ALS (Alternating Least Squares) is a collaborative filtering algorithm commonly used in recommendation systems. It excels at matrix factorization, aiming to predict missing entries in a user-item interaction matrix. The core idea is to decompose this matrix into two lower-dimensional matrices: one capturing user preferences and the other capturing item characteristics.\n",
    "\n",
    "**How ALS Works**\n",
    "\n",
    "- **Matrix Factorization:**  \n",
    "  Given a user-item interaction matrix \\( R \\) (such as ratings or watch ratios), ALS approximates \\( R \\) as the product of two matrices:  \n",
    "  - \\( U \\): Each row represents a user's latent preferences.  \n",
    "  - \\( V \\): Each row represents an item's latent features.  \n",
    "  The objective is to minimize the reconstruction error between \\( R \\) and \\( U \\times V^T \\).\n",
    "\n",
    "- **Alternating Optimization:**  \n",
    "  ALS works by alternately fixing one matrix (e.g., \\( U \\)) and solving for the other (e.g., \\( V \\)), repeating this process until convergence or a set number of iterations.\n",
    "\n",
    "- **Handling Sparsity:**  \n",
    "  Since real-world interaction matrices are typically sparse (with many missing values), ALS is designed to efficiently optimize using only the observed interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028caae",
   "metadata": {},
   "source": [
    "## Fetching dataset\n",
    "(can ignore this part if everyhting already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1qe5hOSBxzIuxBb1G_Ih5X-O65QElollE&export=download&confirm=t&uuid=b2002093-cc6e-4bd5-be47-9603f0b33470\n",
    "' -O KuaiRec.zip\n",
    "unzip KuaiRec.zip -d data_final_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152809c",
   "metadata": {},
   "source": [
    "## Libraries Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1fe6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import get_data_path, matrix_cleanup \n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "DATA_PATH = get_data_path()\n",
    "TRAINED_MODEL = \"trained/pyspark_als_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be7809b",
   "metadata": {},
   "source": [
    "# Step 1: Load the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_matrix = pd.read_csv(f\"{DATA_PATH}/small_matrix.csv\")\n",
    "\n",
    "small_matrix = matrix_cleanup(small_matrix)\n",
    "\n",
    "big_matrix = pd.read_csv(f\"{DATA_PATH}/big_matrix.csv\")\n",
    "\n",
    "big_matrix = matrix_cleanup(big_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115cef26",
   "metadata": {},
   "source": [
    "## Caption Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_category = pd.read_csv(f\"{DATA_PATH}/kuairec_caption_category.csv\", lineterminator='\\n')\n",
    "caption_category.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c33c3b",
   "metadata": {},
   "source": [
    "## Item category\n",
    "\n",
    "We have various video characteristics (such as author_id, video_type, etc.), but these require minimal preprocessing.\n",
    "For content-based filtering, we will utilize video features like the list of tags, applying a straightforward one-hot encoding approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50d5c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values for this data\n",
    "item_categories = pd.read_csv(f\"{DATA_PATH}/item_categories.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6ecca",
   "metadata": {},
   "source": [
    "## Item daily features and User features\n",
    "\n",
    "This dataset is also valuable for content-based filtering.\n",
    "Since it primarily consists of textual data, we will encode the video features using a TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_daily_features = pd.read_csv(f\"{DATA_PATH}/item_daily_features.csv\", lineterminator='\\n')\n",
    "item_daily_features.fillna(-1, inplace=True)\n",
    "\n",
    "user_features = pd.read_csv(f\"{DATA_PATH}/user_features.csv\", lineterminator='\\n')\n",
    "user_features.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e6b5d",
   "metadata": {},
   "source": [
    "# Step 2: Feature Engineering\n",
    "\n",
    "- Extract relevant features from interactions and metadata (such as content tags and user activity history)\n",
    "- Construct the user-item interaction matrix\n",
    "- Optionally, derive features based on time or item popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0ccab",
   "metadata": {},
   "source": [
    "#### Item categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ef3a962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  21  22  23  24  25  26  27  \\\n",
       "0   0   0   0   0   0   0   0   0   1   0  ...   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   1  ...   0   0   0   0   0   0   1   \n",
       "2   0   0   0   0   0   0   0   0   0   1  ...   0   0   0   0   0   0   0   \n",
       "3   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   1   0   \n",
       "4   0   0   0   0   0   1   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "5   0   0   0   0   0   0   1   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "6   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "7   0   0   0   0   0   0   0   0   1   0  ...   0   0   0   0   0   0   0   \n",
       "8   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "9   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "   28  29  30  \n",
       "0   0   0   0  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "5   0   0   0  \n",
       "6   0   0   0  \n",
       "7   0   0   0  \n",
       "8   0   0   0  \n",
       "9   0   0   0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use MultiLabelBinarizer to manage efficiently the feat column\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Transform the feat column to a list (evaluate with python)\n",
    "item_categories[\"feat\"] = item_categories[\"feat\"].apply(eval)\n",
    "\n",
    "item_categories = pd.DataFrame(mlb.fit_transform(item_categories[\"feat\"]), \n",
    "                  columns=mlb.classes_,\n",
    "                  index=item_categories[\"video_id\"])\n",
    "\n",
    "\n",
    "item_categories.reset_index(drop=True, inplace=True)\n",
    "item_categories[item_categories.columns] = item_categories[item_categories.columns].astype(\"int16\")\n",
    "\n",
    "item_categories.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c12e46",
   "metadata": {},
   "source": [
    "#### Item daily features\n",
    "\n",
    "We take the oldest data point for a given video_id.\n",
    "\n",
    "Depending on the complexity, you can choose the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16ee551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FEATURES = [\"video_type\", \"upload_type\"] # \"visible_status\"\n",
    "INT_FEATURES = ['video_duration','video_width', 'video_height', 'music_id', 'video_tag_id','show_cnt', 'show_user_num', 'play_cnt', 'play_user_num',\n",
    "                'play_duration', 'complete_play_cnt', 'complete_play_user_num', 'valid_play_cnt', 'valid_play_user_num', 'long_time_play_cnt',\n",
    "                'long_time_play_user_num', 'short_time_play_cnt', 'short_time_play_user_num', 'play_progress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b1141c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the latest date for each video_id\n",
    "item_daily_features = item_daily_features.loc[item_daily_features.groupby(\"video_id\")[\"date\"].idxmax()].reset_index(drop=True)\n",
    "\n",
    "# One-hot str features\n",
    "text_daily_features = item_daily_features[TEXT_FEATURES]\n",
    "onehotter = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "onehot_array = onehotter.fit_transform(text_daily_features).toarray()\n",
    "\n",
    "# Convert to DataFrame\n",
    "text_daily_features = pd.DataFrame(\n",
    "    onehot_array,\n",
    "    columns=onehotter.get_feature_names_out(TEXT_FEATURES),\n",
    "    index=item_daily_features.index)\n",
    "\n",
    "# Merge the one-hot encoded features back into the original DataFrame\n",
    "item_daily_features = pd.concat([item_daily_features[INT_FEATURES], text_daily_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54f95617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No IDs, because it is the index\n",
    "item_features_map = pd.concat([item_daily_features, item_categories], axis=1)\n",
    "\n",
    "# Column names should be str\n",
    "item_features_map.columns = item_features_map.columns.map(str)\n",
    "\n",
    "# We can keep all the columns\n",
    "item_features_columns = item_features_map.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6336e",
   "metadata": {},
   "source": [
    "### User features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afd188fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_columns = [\n",
    "    \"is_lowactive_period\",\"is_live_streamer\", \"is_video_author\",\n",
    "    \"onehot_feat0\", \"onehot_feat1\", \"onehot_feat2\", \"onehot_feat3\",\n",
    "    \"onehot_feat4\", \"onehot_feat5\", \"onehot_feat6\", \"onehot_feat7\",\n",
    "    \"onehot_feat8\", \"onehot_feat9\", \"onehot_feat10\", \"onehot_feat11\", \n",
    "    \"onehot_feat12\", \"onehot_feat13\", \"onehot_feat14\", \"onehot_feat15\",\n",
    "    \"onehot_feat16\", \"onehot_feat17\"\n",
    "]\n",
    "user_features_map = user_features[user_features_columns].copy()\n",
    "\n",
    "user_features_map[user_features_map.columns] = user_features_map[user_features_map.columns].astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "749576f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_lowactive_period</th>\n",
       "      <th>is_live_streamer</th>\n",
       "      <th>is_video_author</th>\n",
       "      <th>onehot_feat0</th>\n",
       "      <th>onehot_feat1</th>\n",
       "      <th>onehot_feat2</th>\n",
       "      <th>onehot_feat3</th>\n",
       "      <th>onehot_feat4</th>\n",
       "      <th>onehot_feat5</th>\n",
       "      <th>onehot_feat6</th>\n",
       "      <th>...</th>\n",
       "      <th>onehot_feat8</th>\n",
       "      <th>onehot_feat9</th>\n",
       "      <th>onehot_feat10</th>\n",
       "      <th>onehot_feat11</th>\n",
       "      <th>onehot_feat12</th>\n",
       "      <th>onehot_feat13</th>\n",
       "      <th>onehot_feat14</th>\n",
       "      <th>onehot_feat15</th>\n",
       "      <th>onehot_feat16</th>\n",
       "      <th>onehot_feat17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>638</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_lowactive_period  is_live_streamer  is_video_author  onehot_feat0  \\\n",
       "0                    0                 0                0             0   \n",
       "1                    0                 0                0             0   \n",
       "2                    0                 0                0             0   \n",
       "\n",
       "   onehot_feat1  onehot_feat2  onehot_feat3  onehot_feat4  onehot_feat5  \\\n",
       "0             1            17           638             2             0   \n",
       "1             3            25          1021             0             0   \n",
       "2             6             8           402             0             0   \n",
       "\n",
       "   onehot_feat6  ...  onehot_feat8  onehot_feat9  onehot_feat10  \\\n",
       "0             1  ...           184             6              3   \n",
       "1             1  ...           186             6              2   \n",
       "2             0  ...            51             2              3   \n",
       "\n",
       "   onehot_feat11  onehot_feat12  onehot_feat13  onehot_feat14  onehot_feat15  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "\n",
       "   onehot_feat16  onehot_feat17  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_duration</th>\n",
       "      <th>video_width</th>\n",
       "      <th>video_height</th>\n",
       "      <th>music_id</th>\n",
       "      <th>video_tag_id</th>\n",
       "      <th>show_cnt</th>\n",
       "      <th>show_user_num</th>\n",
       "      <th>play_cnt</th>\n",
       "      <th>play_user_num</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5966.0</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "      <td>3350323409</td>\n",
       "      <td>8</td>\n",
       "      <td>3710</td>\n",
       "      <td>2649</td>\n",
       "      <td>2213</td>\n",
       "      <td>1635</td>\n",
       "      <td>19547072</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>886</td>\n",
       "      <td>1015</td>\n",
       "      <td>1812462382</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>94830</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>59</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>212893</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_duration  video_width  video_height    music_id  video_tag_id  \\\n",
       "0          5966.0          720          1280  3350323409             8   \n",
       "1            -1.0          886          1015  1812462382            27   \n",
       "2          8000.0          720          1280           0             9   \n",
       "\n",
       "   show_cnt  show_user_num  play_cnt  play_user_num  play_duration  ...  21  \\\n",
       "0      3710           2649      2213           1635       19547072  ...   0   \n",
       "1        30             25         8              7          94830  ...   0   \n",
       "2        72             59        17             16         212893  ...   0   \n",
       "\n",
       "   22  23  24  25  26  27  28  29  30  \n",
       "0   0   0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   1   0   0   0  \n",
       "2   0   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[3 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Index is the associated IDs for quick creation\n",
    "display(user_features_map.head(3))\n",
    "display(item_features_map.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a735b",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b640606",
   "metadata": {},
   "source": [
    "Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f12a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTION_N = 20_000_000\n",
    "# Either small_matrix or big_matrix\n",
    "DATASET = big_matrix\n",
    "# Number of relevant items to get\n",
    "K = 10\n",
    "# Tolerance for considering a hit\n",
    "WATCH_RATIO_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c6994",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04d43e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of small_matrix relative to big_matrix: 38.89%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion of small_matrix relative to big_matrix: {small_matrix.shape[0] * 100 / big_matrix.shape[0]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13e82d",
   "metadata": {},
   "source": [
    "# Step 3: Model architecture\n",
    "\n",
    "We will use the ALS algorithm from pyspark.ml.recommendation with hyperparameters tuning and cross-validation.\n",
    "\n",
    "The model is cut into 4 parts:\n",
    "- Data preparation and tuning\n",
    "- Model training\n",
    "- Model evaluation\n",
    "- Model saving\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7f59c",
   "metadata": {},
   "source": [
    "### Pyspark imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f682a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_list, col, expr\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel, Model\n",
    "\n",
    "print(f\"Spark version: {pyspark.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KuaiRec ALS\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea58e2e",
   "metadata": {},
   "source": [
    "### Data preparation for Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9284ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# We load directly from the CSV to avoid memory issues\n",
    "small_matrix = spark.read.csv(\n",
    "    f\"{DATA_PATH}/small_matrix.csv\",\n",
    "    header=True,\n",
    "    sep=\",\",\n",
    "    nullValue=\"\",\n",
    "    # We have to infer for correct types\n",
    "    inferSchema=True,\n",
    ").select(\"user_id\", \"video_id\", \"watch_ratio\").na.drop(subset=[\"user_id\", \"video_id\", \"watch_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e203086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a lot of problems, we will not use it for now\n",
    "big_matrix = spark.read.csv(\n",
    "    f\"{DATA_PATH}/big_matrix.csv\",\n",
    "    header=True,\n",
    "    sep=\",\",\n",
    "    inferSchema=True,\n",
    "    nullValue=\"\",\n",
    ").select(\"user_id\", \"video_id\", \"watch_ratio\").na.drop(subset=[\"user_id\", \"video_id\", \"watch_ratio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a0fb3",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0fa9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS model configuration\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    rank=10,\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"video_id\",\n",
    "    ratingCol=\"watch_ratio\",\n",
    "    implicitPrefs=True,\n",
    ")\n",
    "\n",
    "# For CrossValidator\n",
    "params = ParamGridBuilder() \\\n",
    "    .addGrid(als.maxIter, [10, 15]) \\\n",
    "    .addGrid(als.regParam, [0.1]) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "# RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"watch_ratio\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "# CrossValidator\n",
    "cvs = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=params,\n",
    "    evaluator=evaluator,\n",
    "    # Between 2 and 5\n",
    "    numFolds=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00765697",
   "metadata": {},
   "source": [
    "### Training\n",
    "Now with the training, we should have:\n",
    "\n",
    "R ≈ U x V\n",
    "\n",
    "Where:\n",
    "- R is the user-item interaction matrix\n",
    "- U is the user feature matrix\n",
    "- V is the item feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "795db8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = small_matrix.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f41b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ALS model on the train data\n",
    "models : CrossValidatorModel = cvs.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2eeea",
   "metadata": {},
   "source": [
    "### Metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc58f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Take the best model from the CrossValidator\n",
    "pyspark_als_model : Model = models.bestModel\n",
    "predictions = pyspark_als_model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions.na.drop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Rank: {pyspark_als_model.rank}\")\n",
    "print(f\"MaxIter: {pyspark_als_model._java_obj.parent().getMaxIter()}\")\n",
    "print(f\"RegParam: {pyspark_als_model._java_obj.parent().getRegParam()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc33e9",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_als_model.save(TRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac67168",
   "metadata": {},
   "source": [
    "# Step 4: Recommendation\n",
    "\n",
    "- Predict which videos are likely to be enjoyed by each user in the test set\n",
    "- Generate a top-N ranked list of recommendations for each user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85825f1",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d517297",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pyspark_als_model\n",
    "except NameError:\n",
    "    print(\"Model not found. Trying to load it.\")\n",
    "    if os.path.exists(TRAINED_MODEL):\n",
    "        print(\"Model found. Loading it.\")\n",
    "        pyspark_als_model = ALSModel.load(TRAINED_MODEL)\n",
    "        print(\"Model loaded.\")\n",
    "    else:\n",
    "        print(\"Model not found. Please train the model first.\")\n",
    "        raise FileNotFoundError(\"Model not found. Please train the model first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f057ed1",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a12d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not already used Caption Category\n",
    "caption_category = pd.read_csv(f\"{DATA_PATH}/kuairec_caption_category.csv\", lineterminator='\\n')\n",
    "\n",
    "def video_id_to_caption(video_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Get the caption of a video from its id\n",
    "\n",
    "    Args:\n",
    "        video_id (int): The id of the video\n",
    "\n",
    "    Returns:\n",
    "        str: The caption of the video\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the caption from the video_id\n",
    "    match = caption_category[caption_category[\"video_id\"] == video_id][\"caption\"]\n",
    "    # Check not NaN\n",
    "    if not match.empty and match.values[0] == match.values[0]:\n",
    "        return str(match.values[0])\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b679d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All user recommendations\n",
    "recommends = pyspark_als_model.recommendForAllUsers(10)\n",
    "recommends_df = recommends.toPandas()\n",
    "\n",
    "# Explode to have each line as a recommendation\n",
    "recommends_df = recommends_df.explode(\"recommendations\")\n",
    "recommends_df[\"recommendations\"] = recommends_df[\"recommendations\"].apply(\n",
    "    lambda x: f\"{video_id_to_caption(x[0])}\")\n",
    "recommends_df.set_index(\"user_id\", inplace=True)\n",
    "recommends_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 users recommendations\n",
    "\n",
    "# Get the top 5 users\n",
    "\n",
    "print(\"Top 5 users:\")\n",
    "# Get the top 5 users\n",
    "top_5_users = recommends_df.index.unique()[:5].tolist()\n",
    "print(top_5_users)\n",
    "top_users = top_5_users\n",
    "top_users_recommends_df = recommends_df[recommends_df.index.isin(top_users)]\n",
    "top_users_recommends_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f550fd",
   "metadata": {},
   "source": [
    "# Step 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9adbd477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ground_truth = test.groupBy(\"user_id\") \\\n",
    "    .agg(collect_list(\"video_id\").alias(\"true_items\"))\n",
    "\n",
    "predicted = recommends.select(\n",
    "    col(\"user_id\"),\n",
    "    expr(\"transform(recommendations, x -> x.video_id)\").alias(\"pred_items\")\n",
    ")\n",
    "ranking_df = predicted.join(ground_truth, on=\"user_id\", how=\"inner\")\n",
    "\n",
    "ranking_pd = ranking_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a9d9d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(y_true, y_pred, k):\n",
    "    return len(set(y_true) & set(y_pred[:k])) / len(set(y_true)) if y_true else 0\n",
    "\n",
    "def map_at_k(y_true, y_pred, k):\n",
    "    score = 0.0\n",
    "    hit_count = 0.0\n",
    "    for i, p in enumerate(y_pred[:k]):\n",
    "        if p in y_true:\n",
    "            hit_count += 1.0\n",
    "            score += hit_count / (i + 1.0)\n",
    "    return score / min(len(y_true), k) if y_true else 0.0\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k):\n",
    "    relevance = [1 if item in y_true else 0 for item in y_pred[:k]]\n",
    "    return ndcg_score([relevance], [relevance])\n",
    "recalls, maps, ndcgs = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9629d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.0029\n",
      "MAP@10:    0.0805\n",
      "NDCG@10:   0.8760\n"
     ]
    }
   ],
   "source": [
    "for row in ranking_pd.itertuples():\n",
    "    true_items = row.true_items\n",
    "    pred_items = row.pred_items\n",
    "    \n",
    "    recalls.append(recall_at_k(true_items, pred_items, 10))\n",
    "    maps.append(map_at_k(true_items, pred_items, 10))\n",
    "    ndcgs.append(ndcg_at_k(true_items, pred_items, 10))\n",
    "\n",
    "print(f\"Recall@10: {np.mean(recalls):.4f}\")\n",
    "print(f\"MAP@10:    {np.mean(maps):.4f}\")\n",
    "print(f\"NDCG@10:   {np.mean(ndcgs):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
